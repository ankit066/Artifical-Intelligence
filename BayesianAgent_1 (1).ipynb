{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BayesianAgent_1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As7jgRxQYcXO"
      },
      "source": [
        "**0. Your name, roll number and email-id**\n",
        "\n",
        "**Answer in the textbox below**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5shfMLtSYjyA"
      },
      "source": [
        "Ankit Dixit , MT19AI015, ankit.1@iitj.ac.in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApJCBv3w0YeC"
      },
      "source": [
        "**This assignment pertains to concrete architecture for deliberatve agents, and BDI modeling. Our agent wants to either play tennis or watch a movie. We model the agent as an B-D-I agent and implement it with Bayesian Network. Please refer to Module 06-05 for details.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr1MJkFqYuWr"
      },
      "source": [
        "Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1yRukDoYsKJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8a1e4da7-e9f5-462e-d654-046afb699982"
      },
      "source": [
        "!pip install pomegranate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pomegranate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/a1/17396f2bf7e00054ed00fa0667c2a28b3d71a97d4569bacc959abb458212/pomegranate-0.13.5.tar.gz (4.5MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pomegranate) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.9.0b4 in /usr/local/lib/python3.6/dist-packages (from pomegranate) (0.16.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from pomegranate) (2.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pomegranate) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from pomegranate) (3.13)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->pomegranate) (4.4.2)\n",
            "Building wheels for collected packages: pomegranate\n",
            "  Building wheel for pomegranate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pomegranate: filename=pomegranate-0.13.5-cp36-cp36m-linux_x86_64.whl size=15238396 sha256=e9d1cf8835148cee98ef709936e4df4db37ae270151a934f86fe9dd09b279d67\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/d9/0a/0758302ccad41a61aa08ae4985b84d4cab5086e99c92a68560\n",
            "Successfully built pomegranate\n",
            "Installing collected packages: pomegranate\n",
            "Successfully installed pomegranate-0.13.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSzfl0SZ1vaD"
      },
      "source": [
        "**1:** Create a Bayesian Network as shown in slide number 4 to model the belief of the agent. Use the same prior and contitional probabilities. Initialize the network.\n",
        "\n",
        "**Put your code in the space below**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibqnjC3k2RJp"
      },
      "source": [
        "from pomegranate import *\n",
        "import numpy as np\n",
        "#M --> Movie ,A--> Availble ,NA --> Not Availble , S--> Sunny , C --> Cloudy , NM --> Not movie , NT --> Not Tennis \n",
        "weather=DiscreteDistribution({'S':0.7,'C':0.3})\n",
        "Partner=DiscreteDistribution({'A':0.5,'NA':0.5})\n",
        "\n",
        "Movie= ConditionalProbabilityTable([['S','A','M',0.01],\n",
        "                                    ['S','A','NM',0.99],\n",
        "                                    ['S','NA','M',0.60],\n",
        "                                    ['S','NA','NM',0.40],\n",
        "                                    ['C','A','M',0.10],\n",
        "                                    ['C','A','NM',0.90],\n",
        "                                    ['C','NA','M',0.90],\n",
        "                                    ['C','NA','NM',0.10]],[weather,Partner])\n",
        "Tennis=ConditionalProbabilityTable([['S','A','T',0.95],\n",
        "                                    ['S','A','NT',0.05],\n",
        "                                    ['S','NA','T',0.10],\n",
        "                                    ['S','NA','NT',0.90],\n",
        "                                    ['C','A','T',0.10],\n",
        "                                    ['C','A','NT',0.90],\n",
        "                                    ['C','NA','T',0.01],\n",
        "                                    ['C','NA','NT',0.99]],[weather,Partner])\n",
        "\n",
        "S1=Node(weather,name=\"weather\")\n",
        "S2=Node(Partner,name=\"Partner\")\n",
        "S3=Node(Movie,name=\"Movie\")\n",
        "S4=Node(Tennis,name=\"Tennis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKx94qPW3BUE"
      },
      "source": [
        "# Creating Bayesian network \n",
        "network=BayesianNetwork(\"Network to estimate the movie or tennis\")\n",
        "network.add_states(S1,S2,S3,S4)\n",
        "network.add_edge(S1,S3)\n",
        "network.add_edge(S1,S4)\n",
        "network.add_edge(S2,S3)\n",
        "network.add_edge(S2,S4)\n",
        "network.bake()\n",
        "#print(network)\n",
        "#network.plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13CHaXRS3R_b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "549ced99-25a9-4689-8ea6-e4b4b77318a8"
      },
      "source": [
        "observations = { }\n",
        "beliefs = map( str, network.predict_proba( observations ) )\n",
        "print(\"\\n\".join( \"{}\\t\\t{}\".format( state.name, belief ) for state, belief in zip( network.states, beliefs ) ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weather\t\t{\n",
            "    \"class\" : \"Distribution\",\n",
            "    \"dtype\" : \"str\",\n",
            "    \"name\" : \"DiscreteDistribution\",\n",
            "    \"parameters\" : [\n",
            "        {\n",
            "            \"S\" : 0.6999999999999998,\n",
            "            \"C\" : 0.3000000000000002\n",
            "        }\n",
            "    ],\n",
            "    \"frozen\" : false\n",
            "}\n",
            "Partner\t\t{\n",
            "    \"class\" : \"Distribution\",\n",
            "    \"dtype\" : \"str\",\n",
            "    \"name\" : \"DiscreteDistribution\",\n",
            "    \"parameters\" : [\n",
            "        {\n",
            "            \"A\" : 0.5,\n",
            "            \"NA\" : 0.5\n",
            "        }\n",
            "    ],\n",
            "    \"frozen\" : false\n",
            "}\n",
            "Movie\t\t{\n",
            "    \"class\" : \"Distribution\",\n",
            "    \"dtype\" : \"str\",\n",
            "    \"name\" : \"DiscreteDistribution\",\n",
            "    \"parameters\" : [\n",
            "        {\n",
            "            \"NM\" : 0.6365,\n",
            "            \"M\" : 0.36350000000000016\n",
            "        }\n",
            "    ],\n",
            "    \"frozen\" : false\n",
            "}\n",
            "Tennis\t\t{\n",
            "    \"class\" : \"Distribution\",\n",
            "    \"dtype\" : \"str\",\n",
            "    \"name\" : \"DiscreteDistribution\",\n",
            "    \"parameters\" : [\n",
            "        {\n",
            "            \"NT\" : 0.6160000000000001,\n",
            "            \"T\" : 0.384\n",
            "        }\n",
            "    ],\n",
            "    \"frozen\" : false\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6hImc8P2SdU"
      },
      "source": [
        "**2.** What are the marginal probabilities P(M=y) and P(T=y)? Verify against the values given on the slide.\n",
        "\n",
        "What are the desires for the agent? Assume a threshold value of **0.3** for feasible desires. Which of the desires are feasible?\n",
        "\n",
        "**Answer in the text-box below**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etWwQvQY3Gds"
      },
      "source": [
        "The marginal Probabilities for P(M=y) is 0.3635 and P(T=y) is 0.384 , The desires for the agent is choose {M,T} \n",
        "For a thresold value of  0.3 both the desires are satisfying but the agent chooses one with higher marginal probability , so P(T=y)= 0.384 are feasible ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjsb9HPW3SZ6"
      },
      "source": [
        "**3:** The agent wants to pursue a feasible desire with higher marginal probability (playing tennis). That becomes intention and the agent commits to it.\n",
        "\n",
        "The agent needs to act to realize the intention. He looks at the weather and perceives it to be sunny.\n",
        "\n",
        "Instantiate \"Weather\" node (W=s). Update the belief of the agent with this perception. \n",
        "\n",
        "**Put your code in the box below**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azdowHkb4Jxf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "6575559b-c12f-4bce-e5c9-324634b6b992"
      },
      "source": [
        "#Instantiating \"weather\" node (W=s)\n",
        "observations = { 'weather':'S'}\n",
        "beliefs = map( str, network.predict_proba( observations ) )\n",
        "print(\"\\n\".join( \"{}\\t\\t{}\".format( state.name, belief ) for state, belief in zip( network.states, beliefs ) ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weather\t\tS\n",
            "Partner\t\t{\n",
            "    \"class\" : \"Distribution\",\n",
            "    \"dtype\" : \"str\",\n",
            "    \"name\" : \"DiscreteDistribution\",\n",
            "    \"parameters\" : [\n",
            "        {\n",
            "            \"A\" : 0.5,\n",
            "            \"NA\" : 0.5\n",
            "        }\n",
            "    ],\n",
            "    \"frozen\" : false\n",
            "}\n",
            "Movie\t\t{\n",
            "    \"class\" : \"Distribution\",\n",
            "    \"dtype\" : \"str\",\n",
            "    \"name\" : \"DiscreteDistribution\",\n",
            "    \"parameters\" : [\n",
            "        {\n",
            "            \"NM\" : 0.695,\n",
            "            \"M\" : 0.30500000000000005\n",
            "        }\n",
            "    ],\n",
            "    \"frozen\" : false\n",
            "}\n",
            "Tennis\t\t{\n",
            "    \"class\" : \"Distribution\",\n",
            "    \"dtype\" : \"str\",\n",
            "    \"name\" : \"DiscreteDistribution\",\n",
            "    \"parameters\" : [\n",
            "        {\n",
            "            \"NT\" : 0.47500000000000003,\n",
            "            \"T\" : 0.525\n",
            "        }\n",
            "    ],\n",
            "    \"frozen\" : false\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMWaWolu4TF4"
      },
      "source": [
        "**4.** (a) What are the marginal probabilities P(M=y) and P(T=y) now? Which of the desires are feasible now? If there are no feasible desires, *stop here*.\n",
        "\n",
        "(b) If the current intention remains feasible, the agent pursues it. Otherwise, the agent commits to another feasible desire, which will becomes intention. What will be the intention now?\n",
        "\n",
        "**Answer in the text-box below**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ8icF4r4-fm"
      },
      "source": [
        "(a).The marginal probabilites now is P(M=y) = 0.305 and P(T=y) is 0.525 .\n",
        "For a thersold value of 0.3 both are satisfying but agian the agent chooses with higher marginal probabilites so it chooses P(T=y) with 0.525 , \n",
        "(b).The agent persues the current intention i.e. Tennis.\n",
        "So the intenstion now is play Tennis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLA3X3sxYsKh"
      },
      "source": [
        "**5.** The pro-active agent acts further on it's intention. It seeks a partner, but *fails* to get one.\n",
        "\n",
        "Instantiate \"Partner\" node (P=n). Update the belief of the agent.\n",
        "\n",
        "**Put your code in the box below.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C11zAnpZN0z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "7e53f90b-c5cf-46f5-dad0-37a464c77ea0"
      },
      "source": [
        "#Instantiating \"partner \" Node (P=NA)\n",
        "observations = { 'weather':'S','Partner':'NA'}\n",
        "beliefs = map( str, network.predict_proba( observations ) )\n",
        "print(\"\\n\".join( \"{}\\t\\t{}\".format( state.name, belief ) for state, belief in zip( network.states, beliefs ) ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weather\t\tS\n",
            "Partner\t\tNA\n",
            "Movie\t\t{\n",
            "    \"class\" : \"Distribution\",\n",
            "    \"dtype\" : \"str\",\n",
            "    \"name\" : \"DiscreteDistribution\",\n",
            "    \"parameters\" : [\n",
            "        {\n",
            "            \"NM\" : 0.4000000000000001,\n",
            "            \"M\" : 0.5999999999999999\n",
            "        }\n",
            "    ],\n",
            "    \"frozen\" : false\n",
            "}\n",
            "Tennis\t\t{\n",
            "    \"class\" : \"Distribution\",\n",
            "    \"dtype\" : \"str\",\n",
            "    \"name\" : \"DiscreteDistribution\",\n",
            "    \"parameters\" : [\n",
            "        {\n",
            "            \"NT\" : 0.8999999999999999,\n",
            "            \"T\" : 0.10000000000000014\n",
            "        }\n",
            "    ],\n",
            "    \"frozen\" : false\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBnDBDOCZdBL"
      },
      "source": [
        "**6.** \n",
        "(a) What are the marginal probabilities P(M=y) and P(T=y) now? What are the feasible desires? If the current intention is still feasible, *stop here*.\n",
        "\n",
        "(b) Withdraw commitment to the intention, and choose a feasible desire as commitment. What is the commitment now?\n",
        "\n",
        "**Answer in the text-box below**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXoxsQMye4sy"
      },
      "source": [
        "The marginal probabilities for P(M=y) is 0.599 and P(T=y) is 0.10 , In this case the marginal probability for tennis is less than the marginal probability of Movie and also less than the thersold value 0.3, so feasible desire is Movie. \n",
        "(b) So the agent withdraw its commitment i.e. Tennis , and Chooses feasible desire Movie as commitment , The commitment now is Movie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfyL2UNZTjUd"
      },
      "source": [
        "**7.** Is this agent a *learning* agent? Justify your answer.\n",
        "\n",
        "If it is not a learning agent, how can you make it one?\n",
        "\n",
        "**Answer in the text-box below**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4zL7s3ZUr_F"
      },
      "source": [
        "No the agent is not learning agent , because the enviorment is dynamic and it does not have an ability to adapt the changes ,this can be made as learning agent by providing explicit representation of its enviroment,this logical representation captures the real world enviorment in some set of predicates(first order logic), and by providing some perfomace measure which tells which actions leads to new experiences , in addition to that by providing some learning element which tells the agent to which actions might lead to bad experiences.\n",
        "It is also done with reinforcement learning in which each action leads to some reward or penalty . "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GMun5b8a-Rh"
      },
      "source": [
        "**8. DISCUSSIONS**\n",
        "\n",
        "Analyze the steps and the results above. Summarize in plain English how the belief, desire and commitment of agent changed with percepts. \n",
        "\n",
        "Make any salient observations that you think suitable.\n",
        "\n",
        "**Answer in the text-box below**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApPqEuIFbnJI"
      },
      "source": [
        "In our example the belief depends upon the percepts it changes in second cycle when the actions in first cycle fails , if percepts changes (i.e. Partner not availble) we instatiate that node(Partner =NA) and hence the belief revision takes place based on current beilef and perception.\n",
        "Desire : The desire is not gurantee to mature like in our case if we are unable to get the partner in that case our percept changes and hence the desire change from tennis to movie.\n",
        "Commitment :  Agent commitment based on the feasible desires , first we explore only the weather node and based on that we obtain feasible desire , but after the exploration other parent node (Partner), we observe the change in feasible desires(infeasible Tennis) and hence we commit to other option i.e. Movie. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sGVIHFBYzaz"
      },
      "source": [
        "**Congratulations!** Your assignment is complete.\n",
        "\n",
        "**Send review invitation to** hiranmay@gmail.com"
      ]
    }
  ]
}